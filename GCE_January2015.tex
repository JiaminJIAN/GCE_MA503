%GCE of WPI
%by Jiamin JIAN

\documentclass[12pt,a4paper]{ctexart}
\usepackage{CJK}
\usepackage{lipsum}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{amssymb}
\usepackage{epsfig}
\usepackage{float}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{amstext}
\usepackage{blkarray}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{listings}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

\begin{document}


\begin{center}
\textbf{ GCE January, 2015}
\vspace{8pt}

Jiamin JIAN
\end{center}

\vspace{12pt}

$\textbf{Exercise 1:}$

Construct a subset $A \subset \mathbb{R}$ such that $A$ is closed, contains no intervals, is uncountable, and has Lebesgue measure $\frac{1}{2}$ (i.e. $|A| = \frac{1}{2}$). Also explain why your set $A$ has each of the above properties.

\textbf{Hint:} One possible approach here is to adjust the construction of the Cantor set to achieve a Cantor-like set with measure $\frac{1}{2}$, but you don't need to have seen the Cantor set to answer the question.

\vspace{8pt}

$\textbf{Solution:}$

We follow the construction of Cantor set by deleting the open middle forth from a set of line segment. We start by deleting the open middle $(\frac{3}{8}, \frac{5}{8})$ from the interval $[0, 1]$, leaving two line segments $A_{1} = [0, \frac{3}{8}] \cup [\frac{5}{8}, 1]$. Next we do the same thing by deleting $(\frac{5}{32}, \frac{7}{32})$ and $(\frac{25}{32}, \frac{27}{32})$, then we have
\begin{equation*}
    A_{2} = [0, \frac{5}{32}] \cup [\frac{7}{32}, \frac{3}{8}] \cup [\frac{5}{8}, \frac{25}{32}] \cup [\frac{27}{32}, 1].
\end{equation*}
This process is continued as $n \to \infty$, we can get the Cantor-like set $A$.

Since we only delete the open interval from $[0, 1]$ each time, then the union of the intervals we deleted is an open set, thus the Cantor-like set $A$ is closed. We denote $A^{c} = [0, 1] \setminus A$, then we have
\begin{equation*}
    |A^{c}| = \sum_{n = 1}^{\infty} \frac{2^{n-1}}{4^{n}} = \frac{1}{4}  \sum_{n = 1}^{\infty} \Big{(} \frac{1}{2} \Big{)}^{n -1} = \frac{1}{2},
\end{equation*}
thus we know that the measure of Cantor-like set is $\frac{1}{2}$ and it is uncountable. Next we need to show the set $A$ contains no intervals. Suppose the interval $(\alpha, \beta) \in A$. For the $n$-th time we delete the interval whose measure is $\frac{1}{4^{n}}$, so when $n \to \infty$, it is far smaller than $\beta - \alpha$, then we have to separate the interval $(\alpha, \beta)$. Thus similarly with the Cantor set, the Cantor-like set contains no intervals. 


\noindent\rule[0.25\baselineskip]{\textwidth}{0.5pt}

\vspace{8pt}

$\textbf{Exercise 2:}$

(i) Let $(X, \mathcal{A}, \mu)$ be a measure space, and $f_{n}$ a sequence in $L^{1}(X)$. Let $f$ be in $L^{1}(X)$. Assume that $\int f_{n}$ converges to $\int f$, $f_{n}$ converges to $f$ almost everywhere, and for each $n, f_{n} \geq 0$, almost everywhere. Show that $f_{n}$ converges to $f$ in $L^{1}(X)$.

\textbf{Hint:} Set $g_{n} = \min(f_{n}, f)$. Note that $|f_{n} - f| = f + f_{n} - 2 g_{n}$.

(ii) Find a sequence $f_{n}$ in $L^{1}(\mathbb{R})$ and $f$ in $L^{1}(\mathbb{R})$ such that $\int f_{n}$ converges to $\int f$, $f_{n}$ converges to $f$ almost everywhere, but $f_{n}$ does not converge to $f$ in $L^{1}(\mathbb{R})$.
 
\vspace{8pt}
$\textbf{Solution:}$

(i) We set $g_{n} = \min(f_{n}, f)$, then $|f_{n} - f| = f + f_{n} - 2 g_{n}$, thus we can get
\begin{equation*}
    \int_{X}^{} |f_{n} - f| \, d \mu = \int_{X}^{} (f + f_{n} - 2 g_{n}) \, d \mu.
\end{equation*}
Since $f \in L^{1}(X)$ and $f_{n} \in L^{1}(X)$, then we know that $g_{n} \in L^{1}(X)$, so we have
\begin{equation*}
    \int_{X}^{} |f_{n} - f| \, d \mu = \int_{X}^{} f \, d \mu + \int_{X}^{} f_{n} \, d \mu - 2 \int_{X}^{} g_{n} \, d \mu.
\end{equation*}
And by the definition of $g_{n}$, we know that $g_{n}$ converges to $f$ almost everywhere as $f_{n}$ converges to $f$ almost everywhere. As $f_{n} \geq 0$ almost everywhere, then $f \geq 0$ a.e. Since $|g_{n}| \leq |f|$ and $f \in L^{1} (X)$, by the dominate convergence theorem, we know that
\begin{eqnarray*}
    \lim_{n \to \infty} \int_{X}^{} |f_{n} - f| \, d \mu & = & \int_{X}^{} f \, d \mu + \lim_{n \to \infty}  \int_{X}^{} f_{n} \, d \mu - 2 \lim_{n \to \infty} \int_{X}^{} g_{n} \, d \mu \\
    & = & 2 \int_{X}^{} f \, d \mu - 2 \int_{X}^{} \lim_{n \to \infty} g_{n} \, d \mu \\
    & = & 2 \int_{X}^{} f \, d \mu - 2 \int_{X}^{} f \, d \mu = 0,
\end{eqnarray*}
hence we get $f_{n}$ converges to $f$ in $L^{1}(X)$.

(ii) We denote
\begin{equation*}
f_{n} (x) =
\left\{
             \begin{array}{cl}
             \frac{1}{n}, & x \in [-n, 0] \\
             - \frac{1}{n}, & x \in (0, n]
             \end{array}
\right.
\end{equation*}
and $f(x) = 0$, since $|f_{n} \leq \frac{1}{n}|$, we have $f_{n}$ converges to $f$ almost everywhere. As
\begin{equation*}
    \int_{\mathbb{R}}^{} f_{n} \, d \mu = \int_{-n}^{0} \frac{1}{n} \, d \mu + \int_{0}^{n} \Big{(} - \frac{1}{n} \Big{)} \, d \mu = 1 - 1 = 0,
\end{equation*}
we know that $f_{n}$ in $L^{1}(\mathbb{R})$ and $\int f_{n}$ converges to $\int f$. But since
\begin{equation*}
    \int_{\mathbb{R}}^{} |f_{n} - f| \, d \mu = \int_{-n}^{n} \frac{1}{n} \, d \mu = 2,
\end{equation*}
we can get that $f_{n}$ does not converge to $f$ in $L^{1}(\mathbb{R})$.


\noindent\rule[0.25\baselineskip]{\textwidth}{0.5pt}

\vspace{8pt}

$\textbf{Exercise 3:}$

Let $(X, \mathcal{A}, \mu)$ be a measure space.

(i) Let $f$ be in $L^{1}([0, \infty))$. Show that
\begin{equation*}
    \lim_{x \to 0^{+}} \int_{0}^{\infty} f(t) e^{- x t} \, d t = \int_{0}^{\infty} f(t) \, d t
\end{equation*}

(ii) Let $[a, b]$ be an interval in $\mathbb{R}$. If $\Tilde{f}$ is continuous on $[a, b]$ and monotonic, and $g^{'}$ is continuous on $[a, b]$, we can prove that there is a $c$ in $[a, b]$ such that
\begin{equation*}
    \int_{a}^{b} \Tilde{f} g = g(a) \int_{a}^{c} \Tilde{f} + g(b) \int_{c}^{b} \Tilde{f}.
\end{equation*}
Using this result, show that if $g$ is as specified above and $f$ is in $L^{1}([a, b])$, there is a $c$ in $[a, b]$ such that 
\begin{equation*}
    \int_{a}^{b} f g = g(a) \int_{a}^{c} f + g(b) \int_{c}^{b} f.
\end{equation*}

(iii) Let $f$ be in $L^{\infty}([0, \infty))$. Assume that there is a constant $L$ in $\mathbb{R}$ such that $\lim_{x \to \infty} \int_{0}^{x} f = L$. Show that 
\begin{equation*}
    \lim_{x \to 0^{+}} \int_{0}^{ \infty} f(t) e^{- x t} \, d t = L.
\end{equation*}


\vspace{8pt}
$\textbf{Solution:}$

(i) When $x \geq 0$ and $t \geq 0$, we know that $|f(t) e^{- x t}| \leq |f(t)|$. As $f \in L^{1}([0, \infty))$ and for any fixed $t$, $\lim_{x \to 0^{+}} f(t) e^{- x t} = f(t)$, by the dominate convergence theorem, we have
\begin{equation*}
    \lim_{x \to 0^{+}} \int_{0}^{\infty} f(t) e^{- x t} \, d t = \int_{0}^{\infty} \lim_{x \to 0^{+}} f(t) e^{- x t} \, d t = \int_{0}^{\infty} f(t) \, d t. 
\end{equation*}

(ii) Since $\tilde{f}$ is continuous on $[a, b]$, we can introduce $F(x) = \int_{a}^{x} \tilde{f}$, and we know that $F'(x) = \tilde{f}(x)$. Then through integral by parts, we have 
\begin{eqnarray*}
\int_{a}^{b} \tilde{f(x)} g(x) \, d x & = & \int_{a}^{b} g(x) \, d F(x) \\
& = & g(b) F(b) - g(a) F(a) - \int_{a}^{b} g'(x) F(x) \, d x  \\
& = & g(b) \int_{a}^{b} \tilde{f} (x) \, d x - g(a) \int_{a}^{a} \tilde{f} (x) \, d x - \int_{a}^{b} g'(x) F(x) \, d x  \\
& = &  g(b) \int_{a}^{b} \tilde{f} (x) \, d x - \int_{a}^{b} g'(x) F(x) \, d x.
\end{eqnarray*}

Since $g$ is differentiable on $[a, b]$ and monotonic, and $g'$ is continuous on $[a, b]$, we know that $g'$ is integrable in $[a, b]$ and $g'(x) \geq 0$ for all $x \in [a, b]$. By the mean value theorem for integral, there exists $c \in [a, b]$, and
\begin{equation*}
   \int_{a}^{b} g'(x) F(x) \, d x = F(c) \int_{a}^{b} g'(x) \, d x = F(c) (g(b) - g(a)).
\end{equation*}
Thus for this $c \in [a, b]$, we have
\begin{eqnarray*}
\int_{a}^{b} \tilde{f(x)} g(x) \, d x & = & g(b) \int_{a}^{b} \tilde{f} (x) \, d x - F(c) (g(b) - g(a)) \\
& = & g(b) \int_{a}^{b} \tilde{f} (x) \, d x - (g(b) - g(a)) \int_{a}^{c} \tilde{f} (x) \, d x \\
& = & g(b) \int_{a}^{b} \tilde{f} (x) \, d x - g(b) \int_{a}^{c} \tilde{f} (x) \, d x + g(a) \int_{a}^{c} \tilde{f} (x) \, d x  \\
& = &  g(b) \int_{c}^{b} \tilde{f} (x) \, d x + g(a) \int_{a}^{c} \tilde{f} (x) \, d x.
\end{eqnarray*}

Since $C_{c}([a, b])$ is dense in $L^{1}([a, b])$, then we know that for any $f \in L^{1}([0, 1])$, there exists a function sequence $\{f_{n}\} \subset C_{c}([a, b])$ and $\int_{a}^{b} |f_{n} - f| \to 0$ as $n \to + \infty$.
Since $g$ is differentiable on $[a,b]$ and monotonic, we know there exists $K > 0$, and $\forall x \in [a, b]$, we have $|g(x)| \leq K$. So, we have
\begin{equation*}
   \lim_{n \to + \infty} \int_{a}^{b} |g f - g f_{n}| \leq K \lim_{n \to + \infty} \int_{a}^{b}|f - f_{n}| = 0,
\end{equation*}
then by the conclusion we get from (i) we have
\begin{equation*}
   \int_{a}^{b} f g = \lim_{n \to + \infty} \int_{a}^{b} f_{n} g = \lim_{n \to + \infty} \Big{(} g(a) \int_{a}^{c_{n}} f_{n} + g(b) \int_{c_{n}}^{b} f_{n} \Big{)},
\end{equation*}
where $c_{n}$ is depends on $f_{n}$ for each n.

Since $\{c_{n}\} \subset [a, b]$ and $[a, b]$ is compact, there exists a subsequence of $\{c_{n}\}$, which is denoted as $\{c_{n_{k}}\}$, converges to $c$ and $c \in [a, b]$. Thus we have
\begin{eqnarray*}
\int_{a}^{b} f g & = & \lim_{k \to + \infty} \Big{(} g(a) \int_{a}^{c_{n_{k}}} f_{n_{k}} + g(b) \int_{c_{n_{k}}}^{b} f_{n_{k}} \Big{)} \\
& = & \lim_{k \to + \infty} \Big{(} g(a) \int_{a}^{c} f_{n_{k}} + g(a) \int_{c}^{c_{n_{k}}} f_{n_{k}} + g(b) \int_{c_{n_{k}}}^{c} f_{n_{k}} + g(b) \int_{c}^{b} f_{n_{k}} \Big{)} \\
& = &  g(a) \int_{a}^{c} f + g(b) \int_{c}^{b} f + \lim_{k \to + \infty} \Big{(} g(a) \int_{c}^{c_{n_{k}}} f_{n_{k}} +  g(b) \int_{c_{n_{k}}}^{c} f_{n_{k}} \Big{)} \\
& = & g(a) \int_{a}^{c} f + g(b) \int_{c}^{b} f.
\end{eqnarray*}

(iii) For any $K > 0$, we have
\begin{equation*}
    \lim_{x \to 0^{+}} \int_{0}^{ \infty} f(t) e^{- x t} \, d t =  \lim_{x \to 0^{+}} \Big{(} \int_{0}^{K} f(t) e^{- x t} \, d t + \int_{K}^{\infty} f(t) e^{- x t} \, d t \Big{)}
\end{equation*}
let $K \to \infty$, we can get 
\begin{equation*}
    \lim_{x \to 0^{+}} \int_{0}^{ \infty} f(t) e^{- x t} \, d t  =  \lim_{x \to 0^{+}} \lim_{K \to \infty} \int_{0}^{K} f(t) e^{- x t} \, d t, 
\end{equation*}
then we know that 
\begin{eqnarray*}
\lim_{x \to 0^{+}} \int_{0}^{ \infty} f(t) e^{- x t} \, d t 
& = & \lim_{x \to 0^{+}} \lim_{K \to \infty} \Big{(} \int_{0}^{K} f(t) \, d t + \int_{0}^{K} f(t) ( e^{- x t} - 1) \, d t \Big{)} \\
& = & L + \lim_{x \to 0^{+}} \lim_{K \to \infty}  \int_{0}^{K} f(t) ( e^{- x t} - 1) \, d t \\
& = & L + \lim_{K \to \infty} \lim_{x \to 0^{+}} \int_{0}^{K} f(t) ( e^{- x t} - 1) \, d t
\end{eqnarray*}
as $\int_{0}^{K} f(t) e^{- x t} \, d t$ is continuous with $x$ and $K$. As $f(t) \in L^{\infty}([0, \infty))$, we have
\begin{equation*}
    \int_{0}^{K} |f(t)| \, d t \leq K \|f\|_{\infty} < \infty,
\end{equation*}
then we know that $f(t) \in L^{1}([0, K])$. And since $|f(t) ( e^{- x t} - 1)| \leq |f(t)|$ when $x \geq 0, t \geq 0$, by the dominate convergence theorem, we have
\begin{equation*}
    \lim_{x \to 0^{+}} \int_{0}^{K} f(t) (e^{-x t} - 1) \, d t = \int_{0}^{K} f(t) \lim_{x \to 0^{+}} (e^{-x t} - 1) \, d t = 0,
\end{equation*}
hence we can get
\begin{equation*}
    \lim_{x \to 0^{+}} \int_{0}^{ \infty} f(t) e^{- x t} \, d t = L.
\end{equation*}


















\end{document}
